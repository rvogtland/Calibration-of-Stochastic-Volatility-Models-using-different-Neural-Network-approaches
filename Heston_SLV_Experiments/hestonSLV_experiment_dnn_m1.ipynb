{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "import cmath #for complex numbers\n",
    "from scipy.integrate import quad #for numerical integration\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "import time\n",
    "import multiprocessing\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_model_parameters = 6\n",
    "num_strikes = 10\n",
    "num_maturities = 10\n",
    "\n",
    "\n",
    "num_input_parameters = 6\n",
    "num_output_parameters = num_maturities*num_strikes\n",
    "learning_rate = 0.0001\n",
    "num_steps = 5\n",
    "batch_size = 10\n",
    "num_neurons = 40\n",
    "\n",
    "#initial values\n",
    "S0 = 1.0\n",
    "V0 = 0.05\n",
    "r = 0.0\n",
    "\n",
    "\n",
    "contract_bounds = np.array([[0.8*S0,1.2*S0],[5,10]]) #bounds for K,T\n",
    "model_bounds = np.array([[1,2],[0.2,0.8],[-1,0],[2,5],[0.05,0.1],[0.1,0.3]]) #bounds for alpha,beta,rho,a,b,c, make sure alpha>0,2ab>c^2\n",
    "\n",
    "\"\"\"\n",
    "Note: The grid of stirkes and maturities is equidistant here put could be choosen differently for real world application.\n",
    "Note: For the code below to striktly follow the bounds specified above make sure that *_distance x num_* is less than half the distance from the highest to lowest * (* = strikes/maturities). \n",
    "\"\"\"\n",
    "maturities_distance = (contract_bounds[1,1]-contract_bounds[1,0])/(2*num_maturities) \n",
    "strikes_distance = (contract_bounds[0,1]-contract_bounds[0,0])/(2*num_strikes)\n",
    "\n",
    "strikes = np.linspace(contract_bounds[0,0],contract_bounds[0,0]+num_strikes*strikes_distance,num_strikes)\n",
    "maturities = np.linspace(contract_bounds[1,0],contract_bounds[1,0]+num_maturities*maturities_distance,num_maturities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_brownian_motion(n, T, dim, rho):\n",
    "    dt = T/n\n",
    "\n",
    "    dW1 = norm.rvs(size=(dim,n+1) , scale=sqrt(dt))\n",
    "    dW2 = rho * dW1 + np.sqrt(1 - np.power(rho ,2)) * norm.rvs(size=(dim,n+1) , scale=sqrt(dt))\n",
    "        \n",
    "    W1 = np.cumsum(dW1, axis=-1)\n",
    "    W2 = np.cumsum(dW2, axis=-1)\n",
    " \n",
    "    return W1,W2\n",
    "\n",
    "def euler_maruyama(mu,sigma,T,x0,W):\n",
    "    dim = W.shape[0]\n",
    "    n = W.shape[1]-1\n",
    "    Y = np.zeros((dim,n+1))\n",
    "    dt = T/n\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    \n",
    "    Y[:,0] = x0\n",
    "    for i in range(n):\n",
    "        Y[:,i+1] = Y[:,i] + np.multiply(mu(Y[:,i]),dt) + sigma(Y[:,i],i)*sqrt_dt*(W[:,i+1]-W[:,i])\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def heston_SLV(alpha,beta,a,b,c,T,W,Z,V0,S0):\n",
    "   \n",
    "    if not 2*a*b > c*c:\n",
    "        print(\"Error: a= \",a,\", b= \",b,\", c= \",c,\", 2ab>c^2 not fullfilled\")\n",
    "\n",
    "    def mu2(V):\n",
    "        return np.multiply(a,(b-V))\n",
    "    \n",
    "    def sigma2(V,i):\n",
    "        return np.multiply(c,np.sqrt(np.maximum(np.zeros(V.shape[0]),V)))\n",
    "    \n",
    "    V = euler_maruyama(mu2,sigma2,T,V0,Z)\n",
    "    \n",
    "    def mu1(S):\n",
    "        return 0.01*np.ones(S.shape)\n",
    "    \n",
    "    def sigma1(S,i):\n",
    "       \n",
    "        return alpha*np.multiply(np.sqrt(np.maximum(np.zeros(V.shape[0]),V[:,i])),np.power(np.maximum(S,np.zeros(S.shape[0])),1+beta))\n",
    "    \n",
    "    S = euler_maruyama(mu1,sigma1,T,S0,W)\n",
    "    \n",
    "    return S,V\n",
    "\n",
    "def implied_vol(P,K,T):\n",
    "    if not P<S0:\n",
    "        print(\"P<S0 = \",P<S0,\", abitrage!\")\n",
    "        return 0.0\n",
    "    if not P>S0-K*np.exp(-r*T):\n",
    "        print(\"P>S0-K*np.exp(-r*T) = \",P>S0-K*np.exp(-r*T),\", abitrage!\")\n",
    "        return 0.0\n",
    "\n",
    "    def f(sigma):\n",
    "        dplus = (np.log(S0 / K) + (r  + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "        dminus = (np.log(S0 / K) + (r  - 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "        \n",
    "        return S0 * norm.cdf(dplus, 0.0, 1.0) - K * np.exp(-r * T) * norm.cdf(dminus, 0.0, 1.0) - P\n",
    "    \n",
    "    return scipy.optimize.brentq(f, 0.00001, 100000)\n",
    "\n",
    "def reverse_transform_X(X_scaled):\n",
    "    X = np.zeros(X_scaled.shape)\n",
    "    for i in range(num_input_parameters):\n",
    "        X[:,i] = X_scaled[:,i]*(model_bounds[i][1]-model_bounds[i][0]) + model_bounds[i][0]\n",
    "    return X\n",
    "\n",
    "\n",
    "def BS_call_price(sigma,K,T):\n",
    "    dplus = (np.log(S0 / K) + (r  + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    dminus = (np.log(S0 / K) + (r  - 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "\n",
    "    return S0 * norm.cdf(dplus, 0.0, 1.0) - K * np.exp(-r * T) * norm.cdf(dminus, 0.0, 1.0)\n",
    "\n",
    "def HeMC(rho, kappa, theta, xi, T, n):\n",
    "\n",
    "    # Generate a Monte Carlo simulation for the Heston model\n",
    "\n",
    "    # Generate random Brownian Motion\n",
    "    mu = 0\n",
    "    dt = T/n\n",
    "    MU  = np.array([0, 0])\n",
    "    COV = np.matrix([[1, rho], [rho, 1]])\n",
    "    W_   = np.random.multivariate_normal(MU, COV, n)\n",
    "    W_S = W_[:,0]\n",
    "    W_v = W_[:,1]\n",
    "\n",
    "    # Generate paths\n",
    "    vt    = np.zeros(n+1)\n",
    "    vt[0] = V0\n",
    "    St    = np.zeros(n+1)\n",
    "    St[0] = S0\n",
    "    for t in range(1,n):\n",
    "        vt[t] = np.abs(vt[t-1] + kappa*(theta-np.abs(vt[t-1]))*dt + xi*np.sqrt(np.abs(vt[t-1])*dt)*W_v[t])\n",
    "        St[t] = St[t-1]*np.exp((mu - 0.5*vt[t-1])*dt + np.sqrt(vt[t-1]*dt)*W_S[t])\n",
    "\n",
    "    return St\n",
    "\n",
    "def heston_closed(a,b,c,T,K,rho,V0,S0,r=0):\n",
    "    \n",
    "    def char_f(w,a,b,c,T,K,rho,V0,S0,r):\n",
    "        alpha = -0.5*w*(w+complex(0,1))\n",
    "        beta = a - rho*c*w*complex(0,1)\n",
    "        gamma = c*c/2\n",
    "        h = cmath.sqrt(beta*beta-4*alpha*gamma)\n",
    "        rplus = (beta + h)/c/c\n",
    "        rminus = (beta - h)/c/c\n",
    "        g = rminus/rplus\n",
    "        D =  rminus*(1-cmath.exp(-h*T))/(1-g*cmath.exp(-h*T))\n",
    "        C = a*(rminus*T-2/c/c*cmath.log((1-g*cmath.exp(-h*T))/(1-g)))\n",
    "        return cmath.exp(C*b+D*V0+complex(0,1)*w*cmath.log(S0*cmath.exp(r*T)))\n",
    "\n",
    "    def integrand1(w):\n",
    "        i = complex(0,1)\n",
    "        return (cmath.exp(-i*w*cmath.log(K))*char_f(w-i,a,b,c,T,K,rho,V0,S0,r)/i/w/char_f(-i,a,b,c,T,K,rho,V0,S0,r)).real\n",
    "    \n",
    "    def integrand2(w):\n",
    "        i = complex(0,1)\n",
    "        return (cmath.exp(-i*w*cmath.log(K))*char_f(w,a,b,c,T,K,rho,V0,S0,r)/i/w).real\n",
    "    \n",
    "    pi1 = 0.5 + quad(integrand1,0,np.inf)[0]/np.pi\n",
    "    pi2 = 0.5 + quad(integrand2,0,np.inf)[0]/np.pi\n",
    "    \n",
    "    return (S0*pi1 + cmath.exp(-r*T)*K*pi2).real\n",
    "\n",
    "def next_batch_sabr_EM_train(batch_size,contract_bounds,model_bounds):\n",
    "    X_scaled = np.zeros((batch_size,num_input_parameters))\n",
    "    y = np.zeros((batch_size,num_output_parameters))\n",
    "\n",
    "    X_scaled[:,0] = uniform.rvs(size=batch_size) #alpha\n",
    "    X_scaled[:,1] = uniform.rvs(size=batch_size) #beta\n",
    "    X_scaled[:,2] = uniform.rvs(size=batch_size) #rho\n",
    "    X_scaled[:,3] = uniform.rvs(size=batch_size) #a\n",
    "    X_scaled[:,4] = uniform.rvs(size=batch_size) #b\n",
    "    X_scaled[:,5] = uniform.rvs(size=batch_size) #c\n",
    "\n",
    "    X = reverse_transform_X(X_scaled)\n",
    "    #test\n",
    "    #X[:,0] = np.ones(batch_size)\n",
    "    #X[:,1] = np.zeros(batch_size)\n",
    "\n",
    "    n = 200\n",
    "    dim = 40000\n",
    "    for i in range(batch_size):\n",
    "        W,Z = corr_brownian_motion(n,maturities[-1],dim,X[i,2])\n",
    "        S,V = heston_SLV(X[i,0],X[i,1],X[i,3],X[i,4],X[i,5],maturities[-1],W,Z,V0,S0)\n",
    "        #S2 = np.zeros((dim,n+1))\n",
    "        #for c in range(dim):\n",
    "        #    S2[c,:] = HeMC(X[i,2],X[i,3],X[i,4],X[i,5],maturities[-1],n)\n",
    "        \n",
    "        for j in range(num_maturities):\n",
    "            n_current = int(maturities[j]/maturities[-1]*n)\n",
    "            S_T = S[:,n_current]\n",
    "            #S_T2 = S2[:,n_current]\n",
    "            \n",
    "            for k in range(num_strikes):\n",
    "                P = np.mean(np.maximum(S_T-np.ones(dim)*strikes[k],np.zeros(dim)))*np.exp(-r*maturities[j])\n",
    "                #P2 = np.mean(np.maximum(S_T2-np.ones(dim)*strikes[k],np.zeros(dim)))*np.exp(-r*maturities[j])\n",
    "                #P3 = heston_closed(X[i,3],X[i,4],X[i,5],maturities[j],strikes[k],X[i,2],V0,S0,r=0)\n",
    "                y[i,j*num_strikes+k] = implied_vol(P,strikes[k],maturities[j])\n",
    "                #print(P,P2,P3,strikes[k],maturities[j])\n",
    "                #y[i,j*num_strikes+k] = np.exp(-r*maturities[j])*np.mean(np.maximum(S_T-np.ones(dim)*strikes[k],np.zeros(dim)))\n",
    "    return X_scaled,y\n",
    "\n",
    "def g(x, a):\n",
    "    \"\"\"\n",
    "    TBSS kernel applicable to the rBergomi variance process.\n",
    "    \"\"\"\n",
    "    return x**a\n",
    "\n",
    "def b(k, a):\n",
    "    \"\"\"\n",
    "    Optimal discretisation of TBSS process for minimising hybrid scheme error.\n",
    "    \"\"\"\n",
    "    return ((k**(a+1)-(k-1)**(a+1))/(a+1))**(1/a)\n",
    "\n",
    "def cov(a, n):\n",
    "    \"\"\"\n",
    "    Covariance matrix for given alpha and n, assuming kappa = 1 for\n",
    "    tractability.\n",
    "    \"\"\"\n",
    "    cov = np.array([[0.,0.],[0.,0.]])\n",
    "    cov[0,0] = 1./n\n",
    "    cov[0,1] = 1./((1.*a+1) * n**(1.*a+1))\n",
    "    cov[1,1] = 1./((2.*a+1) * n**(2.*a+1))\n",
    "    cov[1,0] = cov[0,1]\n",
    "    return cov\n",
    "\n",
    "def bs(F, K, V, o = 'call'):\n",
    "    \"\"\"\n",
    "    Returns the Black call price for given forward, strike and integrated\n",
    "    variance.\n",
    "    \"\"\"\n",
    "    # Set appropriate weight for option token o\n",
    "    w = 1\n",
    "    if o == 'put':\n",
    "        w = -1\n",
    "    elif o == 'otm':\n",
    "        w = 2 * (K > 1.0) - 1\n",
    "\n",
    "    sv = np.sqrt(V)\n",
    "    d1 = np.log(F/K) / sv + 0.5 * sv\n",
    "    d2 = d1 - sv\n",
    "    P = w * F * norm.cdf(w * d1) - w * K * norm.cdf(w * d2)\n",
    "    return P\n",
    "\n",
    "def bsinv(P, F, K, t, o = 'call'):\n",
    "    \"\"\"\n",
    "    Returns implied Black vol from given call price, forward, strike and time\n",
    "    to maturity.\n",
    "    \"\"\"\n",
    "    # Set appropriate weight for option token o\n",
    "    w = 1\n",
    "    if o == 'put':\n",
    "        w = -1\n",
    "    elif o == 'otm':\n",
    "        w = 2 * (K > 1.0) - 1\n",
    "\n",
    "    # Ensure at least instrinsic value\n",
    "    P = np.maximum(P, np.maximum(w * (F - K), 0))\n",
    "\n",
    "    def error(s):\n",
    "        return bs(F, K, s**2 * t, o) - P\n",
    "    s = brentq(error, 1e-9, 1e+9)\n",
    "    return s\n",
    "\n",
    "vec_bsinv = np.vectorize(bsinv)\n",
    "\n",
    "class rBergomi(object):\n",
    "    \"\"\"\n",
    "    Class for generating paths of the rBergomi model.\n",
    "    \"\"\"\n",
    "    def __init__(self, n = 100, N = 1000, T = 1.00, a = -0.4):\n",
    "        \"\"\"\n",
    "        Constructor for class.\n",
    "        \"\"\"\n",
    "        # Basic assignments\n",
    "        self.T = T # Maturity\n",
    "        self.n = n # Granularity (steps per year)\n",
    "        self.dt = 1.0/self.n # Step size\n",
    "        self.s = int(self.n * self.T) # Steps\n",
    "        self.t = np.linspace(0, self.T, 1 + self.s)[np.newaxis,:] # Time grid\n",
    "        self.a = a # Alpha\n",
    "        self.N = N # Paths\n",
    "\n",
    "        # Construct hybrid scheme correlation structure for kappa = 1\n",
    "        self.e = np.array([0,0])\n",
    "        self.c = cov(self.a, self.n)\n",
    "\n",
    "    def dW1(self):\n",
    "        \"\"\"\n",
    "        Produces random numbers for variance process with required\n",
    "        covariance structure.\n",
    "        \"\"\"\n",
    "        rng = np.random.multivariate_normal\n",
    "        return rng(self.e, self.c, (self.N, self.s))\n",
    "\n",
    "    def Y(self, dW):\n",
    "        \"\"\"\n",
    "        Constructs Volterra process from appropriately\n",
    "        correlated 2d Brownian increments.\n",
    "        \"\"\"\n",
    "        Y1 = np.zeros((self.N, 1 + self.s)) # Exact integrals\n",
    "        Y2 = np.zeros((self.N, 1 + self.s)) # Riemann sums\n",
    "\n",
    "        # Construct Y1 through exact integral\n",
    "        for i in np.arange(1, 1 + self.s, 1):\n",
    "            Y1[:,i] = dW[:,i-1,1] # Assumes kappa = 1\n",
    "\n",
    "        # Construct arrays for convolution\n",
    "        G = np.zeros(1 + self.s) # Gamma\n",
    "        for k in np.arange(2, 1 + self.s, 1):\n",
    "            G[k] = g(b(k, self.a)/self.n, self.a)\n",
    "\n",
    "        X = dW[:,:,0] # Xi\n",
    "\n",
    "        # Initialise convolution result, GX\n",
    "        GX = np.zeros((self.N, len(X[0,:]) + len(G) - 1))\n",
    "\n",
    "        # Compute convolution, FFT not used for small n\n",
    "        # Possible to compute for all paths in C-layer?\n",
    "        for i in range(self.N):\n",
    "            GX[i,:] = np.convolve(G, X[i,:])\n",
    "\n",
    "        # Extract appropriate part of convolution\n",
    "        Y2 = GX[:,:1 + self.s]\n",
    "\n",
    "        # Finally contruct and return full process\n",
    "        Y = np.sqrt(2 * self.a + 1) * (Y1 + Y2)\n",
    "        return Y\n",
    "\n",
    "    def dW2(self):\n",
    "        \"\"\"\n",
    "        Obtain orthogonal increments.\n",
    "        \"\"\"\n",
    "        return np.random.randn(self.N, self.s) * np.sqrt(self.dt)\n",
    "\n",
    "    def dB(self, dW1, dW2, rho = 0.0):\n",
    "        \"\"\"\n",
    "        Constructs correlated price Brownian increments, dB.\n",
    "        \"\"\"\n",
    "        self.rho = rho\n",
    "        dB = rho * dW1[:,:,0] + np.sqrt(1 - rho**2) * dW2\n",
    "        return dB\n",
    "\n",
    "    def V(self, Y, xi = 1.0, eta = 1.0):\n",
    "        \"\"\"\n",
    "        rBergomi variance process.\n",
    "        \"\"\"\n",
    "        self.xi = xi\n",
    "        self.eta = eta\n",
    "        a = self.a\n",
    "        t = self.t\n",
    "        V = xi * np.exp(eta * Y - 0.5 * eta**2 * t**(2 * a + 1))\n",
    "        return V\n",
    "\n",
    "    def S(self, V, dB, S0 = 1):\n",
    "        \"\"\"\n",
    "        rBergomi price process.\n",
    "        \"\"\"\n",
    "        self.S0 = S0\n",
    "        dt = self.dt\n",
    "        rho = self.rho\n",
    "\n",
    "        # Construct non-anticipative Riemann increments\n",
    "        increments = np.sqrt(V[:,:-1]) * dB - 0.5 * V[:,:-1] * dt\n",
    "\n",
    "        # Cumsum is a little slower than Python loop.\n",
    "        integral = np.cumsum(increments, axis = 1)\n",
    "\n",
    "        S = np.zeros_like(V)\n",
    "        S[:,0] = S0\n",
    "        S[:,1:] = S0 * np.exp(integral)\n",
    "        return S\n",
    "\n",
    "    def S1(self, V, dW1, rho, S0 = 1):\n",
    "        \"\"\"\n",
    "        rBergomi parallel price process.\n",
    "        \"\"\"\n",
    "        dt = self.dt\n",
    "\n",
    "        # Construct non-anticipative Riemann increments\n",
    "        increments = rho * np.sqrt(V[:,:-1]) * dW1[:,:,0] - 0.5 * rho**2 * V[:,:-1] * dt\n",
    "\n",
    "        # Cumsum is a little slower than Python loop.\n",
    "        integral = np.cumsum(increments, axis = 1)\n",
    "\n",
    "        S = np.zeros_like(V)\n",
    "        S[:,0] = S0\n",
    "        S[:,1:] = S0 * np.exp(integral)\n",
    "        return S\n",
    "\n",
    "def implied_vols_surface(theta):\n",
    "    #INPUT: theta = (H,eta,rho,lambda)\n",
    "    #OUTPUT: implied volatility surface\n",
    "\n",
    "    IVS = np.zeros((num_maturities,num_strikes))\n",
    "\n",
    "    n = 100 \n",
    "\n",
    "    rB = rBergomi(n = n, N = 10000, T = maturities[-1], a = theta[0]-0.5)\n",
    "\n",
    "    dW1 = rB.dW1()\n",
    "    dW2 = rB.dW2()\n",
    "\n",
    "    Y = rB.Y(dW1)\n",
    "\n",
    "    dB = rB.dB(dW1, dW2, rho = theta[2])\n",
    "\n",
    "    V = rB.V(Y, xi = theta[3], eta = theta[1])\n",
    "\n",
    "    S = rB.S(V, dB) \n",
    "    for i in range(num_maturities):\n",
    "        ST = S[:,int(n*maturities[i])][:,np.newaxis]\n",
    "        call_payoffs = np.maximum(ST - strikes,0)\n",
    "        \n",
    "        call_prices = np.mean(call_payoffs, axis = 0)[:,np.newaxis]\n",
    "        K = strikes[np.newaxis,:]\n",
    "        implied_vols = vec_bsinv(call_prices, 1.0, np.transpose(K), maturities[i])\n",
    "      \n",
    "        IVS[i,:] = implied_vols[:,0]\n",
    "    \n",
    "    return IVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.81 s ± 37.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
    }
   ],
   "source": [
    "#hestonLV\n",
    "%timeit next_batch_sabr_EM_train(1,contract_bounds,model_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.51 s ± 8.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
    }
   ],
   "source": [
    "#rbergomi\n",
    "theta = [0.1,0.2,-0.2,0.1]\n",
    "%timeit implied_vols_surface(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595494460507",
   "display_name": "Python 3.5.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}