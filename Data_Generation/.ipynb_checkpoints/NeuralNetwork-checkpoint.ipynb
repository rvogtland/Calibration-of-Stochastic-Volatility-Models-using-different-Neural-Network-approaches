{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data and Scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.20207581 1.92239056 0.49583491 0.20336394]\n",
      " [1.57512242 1.44138507 0.90424946 0.18410172]\n",
      " [1.04617186 1.76098485 0.06558515 0.81524428]\n",
      " [1.43554335 1.87604335 0.68017867 0.34929233]\n",
      " [1.04482755 1.11180824 0.693482   0.42504613]\n",
      " [1.11737054 1.00940002 0.72709671 0.84580623]\n",
      " [1.44207922 1.38795771 0.78484338 0.6244721 ]\n",
      " [1.1884379  1.66271561 0.33986351 0.06144064]\n",
      " [1.77297475 1.81506917 0.36689373 0.98140273]\n",
      " [1.22890027 1.17113486 0.21459103 0.29242623]]\n",
      "[[0.98416443 1.64142053]\n",
      " [1.00456183 1.35890458]\n",
      " [0.99018326 1.49340831]\n",
      " [1.00372842 1.67447324]\n",
      " [1.00327831 1.07150625]\n",
      " [0.97183347 0.9940148 ]\n",
      " [0.98204588 1.28494616]\n",
      " [1.0052962  1.46118496]\n",
      " [0.98318762 1.67426659]\n",
      " [0.98679588 1.11813847]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "data = genfromtxt('./data/heston_data.csv', delimiter=',')\n",
    "X_data = data[:,1:5]\n",
    "Y_data = data[:,5:7]\n",
    "print(X_data[:10,:])\n",
    "print(Y_data[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_data)\n",
    "Y_scaled = scaler.fit_transform(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Placeholders and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 4\n",
    "num_outputs = 2\n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 10\n",
    "num_neurons = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, num_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "#Layers\n",
    "hidden1 = fully_connected(X, num_neurons, activation_fn=tf.nn.elu)\n",
    "hidden2 = fully_connected(hidden1, num_neurons, activation_fn=tf.nn.elu)\n",
    "outputs = fully_connected(hidden2, num_outputs, activation_fn=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))  # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 0.06332244\n",
      "100 \tMSE: 0.041817363\n",
      "200 \tMSE: 0.039610367\n",
      "300 \tMSE: 0.039483994\n",
      "400 \tMSE: 0.039445452\n",
      "500 \tMSE: 0.039410092\n",
      "600 \tMSE: 0.03937421\n",
      "700 \tMSE: 0.039334573\n",
      "800 \tMSE: 0.039290458\n",
      "900 \tMSE: 0.039242715\n",
      "1000 \tMSE: 0.039191958\n",
      "1100 \tMSE: 0.039140806\n",
      "1200 \tMSE: 0.039092913\n",
      "1300 \tMSE: 0.03905182\n",
      "1400 \tMSE: 0.03901755\n",
      "1500 \tMSE: 0.03898793\n",
      "1600 \tMSE: 0.038959697\n",
      "1700 \tMSE: 0.03893001\n",
      "1800 \tMSE: 0.03889642\n",
      "1900 \tMSE: 0.038855292\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for iteration in range(num_steps):\n",
    "        sess.run(train,feed_dict={X: X_scaled, y: Y_scaled})\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            \n",
    "            mse = loss.eval(feed_dict={X: X_scaled, y: Y_scaled})\n",
    "            print(iteration, \"\\tMSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
