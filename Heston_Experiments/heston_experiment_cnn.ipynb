{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a grid of strikes and maturities\n",
    "T = np.array([2,2.5,3,3.5,4,4.5,5,5.5])\n",
    "K = np.array([0.6,0.65,0.7,0.75,0.8,0.9,1.0,1.1])\n",
    "\n",
    "num_input_parameters = len(T)*len(K)*4\n",
    "num_output_parameters = len(T)*len(K)\n",
    "learning_rate = 0.1\n",
    "num_steps = 20\n",
    "batch_size = 6\n",
    "num_neurons = 15\n",
    "\n",
    "#initial values\n",
    "S0 = 1.0\n",
    "V0 = 0.2\n",
    "r = 0.15\n",
    "\n",
    "#bounds for a,b,c,rho, make sure 2ab>c^2\n",
    "bounds = np.array([[1,3],[0.1,0.6],[0,0.1],[0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Batch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_brownian_motion(n, T, dim, rho):\n",
    "    dt = T/n\n",
    "\n",
    "    dW1 = norm.rvs(size=(dim,n+1) , scale=sqrt(dt))\n",
    "    dW2 = rho * dW1 + np.sqrt(1 - np.power(rho ,2)) * norm.rvs(size=(dim,n+1) , scale=sqrt(dt))\n",
    "        \n",
    "    W1 = np.cumsum(dW1, axis=-1)\n",
    "    W2 = np.cumsum(dW2, axis=-1)\n",
    " \n",
    "    return W1,W2\n",
    "\n",
    "def euler_maruyama(mu,sigma,T,x0,W):\n",
    "    dim = W.shape[0]\n",
    "    n = W.shape[1]-1\n",
    "    Y = np.zeros((dim,n+1))\n",
    "    dt = T/n\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    for l in range(dim):\n",
    "        Y[l,0] = x0\n",
    "        for i in range(n):\n",
    "            Y[l,i+1] = Y[l,i] + np.multiply(mu(Y[l,i],l,i),dt) + sigma(Y[l,i],l,i)*sqrt_dt*(W[l,i+1]-W[l,i])\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def heston(a,b,c,T,W,Z,V0,S0):\n",
    "    #assert(2*a*b > c*c) \n",
    "    \n",
    "    def mu2(V,i,k):\n",
    "        return np.multiply(a,(b-V))\n",
    "    \n",
    "    def sigma2(V,i,k):\n",
    "        return np.multiply(c,np.sqrt(np.maximum(0.0,V)))\n",
    "    \n",
    "    V = euler_maruyama(mu2,sigma2,T,V0,Z)\n",
    "    \n",
    "    def mu1(S,i,k):\n",
    "        return 0.0\n",
    "    \n",
    "    def sigma1(S,i,k):\n",
    "        return np.multiply(np.sqrt(np.maximum(0.0,V[i,k])),S)\n",
    "    \n",
    "    S = euler_maruyama(mu1,sigma1,T,S0,W)\n",
    "    \n",
    "    return S,V\n",
    "\n",
    "def reverse_transform_tensor(X_scaled):\n",
    "    X = np.zeros(X_scaled.shape)\n",
    "    for i in range(X_scaled.shape[-1]):\n",
    "        X[:,:,:,i] = X_scaled[:,:,:,i]*(bounds[i][1]-bounds[i][0]) + bounds[i][0]\n",
    "    return X\n",
    "\n",
    "def next_batch_heston_EM_train(batch_size,bounds):\n",
    "    X = np.zeros((batch_size,len(T),len(K),4))\n",
    "    X_scaled = np.zeros((batch_size,len(T),len(K),4))\n",
    "    y = np.zeros((batch_size,len(T)*len(K)))\n",
    "\n",
    "    X_scaled = uniform.rvs(size=(batch_size,len(T),len(K),4))\n",
    "    \n",
    "    X = reverse_transform_tensor(X_scaled)\n",
    "\n",
    "    n = 100\n",
    "    dim = 10\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        for j in range(len(T)):\n",
    "            for k in range(len(K)):\n",
    "                W,Z = corr_brownian_motion(n,T[j],dim,X[i,j,k,3])\n",
    "                S,V = heston(X[i,j,k,0],X[i,j,k,1],X[i,j,k,2],T[j],W,Z,V0,S0)\n",
    "                S_T = S[:,n]\n",
    "        \n",
    "                y[i,j*len(K)+k] = np.exp(-r*T[j])*np.mean(np.maximum(S_T-K[k],np.zeros(dim)))\n",
    "    \n",
    "    return X_scaled,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "\"\"\"\n",
    "Create a 2D convolution using builtin conv2d from TF. From those docs:\n",
    "Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "Given an input tensor of shape [batch_size, len(T), len(K), #params] and a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels], this op performs the following:\n",
    "Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].\n",
    "Extracts image patches from the input tensor to form a virtual tensor of shape [batch_size, len(T), len()K, filter_height * filter_width * #params].\n",
    "For each patch, right-multiplies the filter matrix and the image patch vector.\n",
    "\"\"\"\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\"\"\"\n",
    "Args:\n",
    "  value: A 4-D `Tensor` with shape `[batch_size, len(T), len(K), #params]` and\n",
    "    type `tf.float32`.\n",
    "  ksize: A list of ints that has length >= 4.  The size of the window for\n",
    "    each dimension of the input tensor.\n",
    "  strides: A list of ints that has length >= 4.  The stride of the sliding\n",
    "    window for each dimension of the input tensor.\n",
    "  padding: A string, either `'VALID'` or `'SAME'`. \n",
    "\"\"\"\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=[None,len(T),len(K),4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,len(T)*len(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/robinvogtland/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `layer.__call__` method instead.\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "3x3 Filter\n",
    "4 `Ã¬mages` as input\n",
    "32 outputs\n",
    "\"\"\"\n",
    "convo_1 = convolutional_layer(X,shape=[3,3,4,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "\n",
    "\"\"\"\n",
    "3x3 Filter\n",
    "32 inputs\n",
    "64 outputs\n",
    "\"\"\"\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[3,3,32,32])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "\n",
    "\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,int(len(T)/2)*32])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n",
    "\n",
    "outputs = fully_connected(full_layer_one, len(T)*len(K), activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "loss = tf.reduce_mean(tf.sqrt(tf.square(outputs - y)))  # MSE\n",
    "\n",
    "#Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 \tRMSE: 452.9606\n4 \tRMSE: 2.1978002\n8 \tRMSE: 0.33170107\n12 \tRMSE: 0.118288405\n16 \tRMSE: 0.57613575\n"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for iteration in range(num_steps):\n",
    "        \n",
    "        X_batch,Y_batch = next_batch_heston_EM_train(batch_size,bounds)\n",
    "   \n",
    "        sess.run(train,feed_dict={X: X_batch, y: Y_batch})\n",
    "        \n",
    "        if iteration % 4 == 0:\n",
    "            \n",
    "            rmse = loss.eval(feed_dict={X: X_batch, y: Y_batch})\n",
    "            print(iteration, \"\\tRMSE:\", rmse)\n",
    "    \n",
    "    saver.save(sess, \"./models/heston_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true = [2.1,0.5,0.05,0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNprediction(theta):\n",
    "    x = np.zeros((1,len(T),len(K),len(theta)))\n",
    "    for i in range(len(T)):\n",
    "        for j in range(len(K)):\n",
    "            x[0,i,j,:] = theta\n",
    "    return sess.run(outputs,feed_dict={X: x})\n",
    "\n",
    "def NNgradientpred(theta):\n",
    "    x = np.zeros((1,len(T),len(K),len(theta)))\n",
    "    for i in range(len(T)):\n",
    "        for j in range(len(K)):\n",
    "            x[0,i,j,:] = theta   \n",
    "    grad = np.zeros((len(T)*len(K),len(theta)))\n",
    "    \n",
    "    delta = 0.000001\n",
    "    for i in range(len(theta)):\n",
    "        h = np.zeros(x.shape)\n",
    "        h[0,:,:,i] = delta\n",
    "        \n",
    "        #two point gradient\n",
    "        #grad[i] = (sess.run(outputs,feed_dict={X: x+h}) - sess.run(outputs,feed_dict={X: x-h}))/2/delta\n",
    "\n",
    "        #four point gradient\n",
    "        grad[:,i] = (-sess.run(outputs,feed_dict={X: x+2*h})+8*sess.run(outputs,feed_dict={X: x+h})-8*sess.run(outputs,feed_dict={X: x-h}) +sess.run(outputs,feed_dict={X: x-2*h}))/12/delta\n",
    "\n",
    "    return grad\n",
    "\n",
    "#input: theta in order a,b,c,rho\n",
    "def CostFunc(theta):\n",
    "\n",
    "    if theta[3]<=0:\n",
    "        theta[3] = 0.01\n",
    "    if theta[3]>=1:\n",
    "        theta[3] = 0.99\n",
    "    if theta[2]<=0:\n",
    "        theta[2] = 0.1\n",
    "    if 2*theta[0]*theta[1]<=theta[2]*theta[2]:\n",
    "        theta[0] += theta[2]\n",
    "        theta[1] += theta[2]\n",
    "   \n",
    "    heston_ = np.zeros(num_output_parameters)\n",
    "    for i in range(len(T)):\n",
    "        for j in range(len(K)):\n",
    "            n = 500\n",
    "            dim = 20\n",
    "            W,Z = corr_brownian_motion(n,T[i],dim,theta_true[3])\n",
    "            S,V = heston(theta_true[0],theta_true[1],theta_true[2],K[j],W,Z,V0,S0)\n",
    "            S_T = S[:,n]\n",
    "        \n",
    "            heston_[i*len(K)+j] = np.exp(-r*T[i])*np.mean(np.maximum(S_T-K[j],np.zeros(dim)))\n",
    "            \n",
    "    return (NNprediction(theta)-heston_)[0]\n",
    "\n",
    "\n",
    "def Jacobian(theta):\n",
    "\n",
    "    if theta[3]<=0:\n",
    "        theta[3] = 0.01\n",
    "    if theta[3]>=1:\n",
    "        theta[3] = 0.99\n",
    "    if theta[2]<=0:\n",
    "        theta[2] = 0.1\n",
    "    if 2*theta[0]*theta[1]<=theta[2]*theta[2]:\n",
    "        theta[0] += theta[2]\n",
    "        theta[1] += theta[2]\n",
    "\n",
    "    return NNgradientpred(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                          \n",
    "    #saver.restore(sess, \"./models/heston_closed_nn\") \n",
    "    saver.restore(sess, \"./models/heston_cnn\")   \n",
    "\n",
    "    init = [bounds[0,0],bounds[1,0],bounds[2,0],bounds[3,0]]\n",
    "    init_best = init\n",
    "    \n",
    "    cost_old = 1000000\n",
    "    n = 3\n",
    "    for a in range(n):\n",
    "        print(a)\n",
    "        init_new = [bounds[0,0],bounds[1,0],bounds[2,0],bounds[3,0]]\n",
    "        init_new[0] += 1/(n+1)*(bounds[0,1]-bounds[0,0])\n",
    "        for b in range(n):\n",
    "            init_new[1] += 1/(n+1)*(bounds[1,1]-bounds[1,0])\n",
    "            init_new[2] = bounds[2,0]\n",
    "            init_new[3] = bounds[3,0]\n",
    "            for c in range(n):\n",
    "                init_new[2] += 1/(n+1)*(bounds[2,1]-bounds[2,0])\n",
    "                init_new[3] = bounds[3,0]\n",
    "                for d in range(n):\n",
    "                    init_new[3] += 1/(n+1)*(bounds[3,1]-bounds[3,0])\n",
    "                    \n",
    "                    cost_new = CostFunc(init_new)\n",
    "                    if np.linalg.norm(cost_new) < np.linalg.norm(cost_old):\n",
    "                        init_best = init_new \n",
    "                    cost_old = cost_new\n",
    "            \n",
    "    init = init_best\n",
    "print(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                          \n",
    "    saver.restore(sess, \"./models/heston_cnn\")      \n",
    "    \n",
    "    init = [2,0.3,0.09,0.6]\n",
    "    bnds = ([bounds[0,0],bounds[1,0],bounds[2,0],bounds[3,0]],[bounds[0,1],bounds[1,1],bounds[2,1],bounds[3,1]])\n",
    "    X_batch,Y_batch = next_batch_heston_EM_train(batch_size,bounds)\n",
    "\n",
    "    I=scipy.optimize.least_squares(CostFunc,init,Jacobian,bounds=bnds,gtol=1E-10,xtol=1E-10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted Theta:  [2.9119428  0.57358284 0.09559714 0.96477712]\nTrue Theta:  [2.1, 0.5, 0.05, 0.4]\n"
    }
   ],
   "source": [
    "theta_nn = I.x\n",
    "print(\"Predicted Theta: \",theta_nn)\n",
    "print(\"True Theta: \",theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RMSE:  0.034596460157678484\n"
    }
   ],
   "source": [
    "RMSE = 0\n",
    "price_true = np.zeros((len(T),len(K)))\n",
    "price_opt_params = np.zeros((len(T),len(K)))\n",
    "theta_nn =  [1.1,0.3,0.05,0.2]\n",
    "for i in range(len(T)):\n",
    "    for j in range(len(K)):\n",
    "        #price_true = heston_closed(theta_true[0],theta_true[1],theta_true[2],T[i],K[j],theta_true[3],V0,S0)\n",
    "        n = 100\n",
    "        dim = 20\n",
    "        W,Z = corr_brownian_motion(n,T[i],dim,theta_true[3])\n",
    "        S,V = heston(theta_true[0],theta_true[1],theta_true[2],T[i],W,Z,V0,S0)\n",
    "        S_T = S[:,n]\n",
    "        price_true[i,j] = np.exp(-r*T[i])*np.mean(np.maximum(S_T-K[j],np.zeros(dim)))\n",
    "        \n",
    "        #price_opt_params = heston_closed(Theta[i,j,0],Theta[i,j,1],Theta[i,j,2],T[i],K[j],Theta[i,j,3],V0,S0)\n",
    "        W,Z = corr_brownian_motion(n,T[i],dim,theta_nn[3])\n",
    "        S,V = heston(theta_nn[0],theta_nn[1],theta_nn[2],T[i],W,Z,V0,S0)\n",
    "        S_T = S[:,n]\n",
    "        price_opt_params[i,j] = np.exp(-r*T[i])*np.mean(np.maximum(S_T-K[j],np.zeros(dim)))\n",
    "        RMSE += np.power(price_true[i,j]-price_opt_params[i,j],2)\n",
    "RMSE = np.sqrt(RMSE/(len(T)*len(K)))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}